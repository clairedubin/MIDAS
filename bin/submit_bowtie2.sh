#!/bin/bash                         #-- what is the language of this shell
#                                   #-- Any line that starts with #$ is an instruction to SGE
#$ -S /bin/bash                     #-- the shell for the job
#$ -o /wynton/group/pollard/czhao/predict1/bt2_out                       #-- output directory (fill in)
#$ -e /wynton/group/pollard/czhao/predict1/bt2_err                       #-- error directory (fill in)
#$ -V                               #-- pass all environment variables
#$ -cwd                             #-- tell the job that it should start in your working directory
##$ -r y                            #-- tell the system that if a job crashes, it should be restarted
##$ -j y                            #-- tell the system that the STDERR and STDOUT should be joined
#$ -pe smp 8
#$ -l mem_free=2G                   #-- submits on nodes with enough free memory (required)
#$ -l arch=lx-amd64                 #-- SGE resources (CPU type)
#$ -l scratch=100G                   #-- SGE resources (home and scratch disks)
#$ -l h_rt=336:00:00                #-- runtime limit (see above; this requests 24 hours)
#$ -t 1-794                        #-- Array job: submit XX jobs to the job queues at once.
#$ -tc 794                         #-- specify the maximum number of concurrent tasks


module load Sali anaconda
source activate bwa-metasnv

echo "Hello world, I’m running on node ${HOSTNAME}"
JB_LAB=part_${SGE_TASK_ID}
TREADS=${NSLOTS:-1}


CWDIR="/wynton/home/pollard/czhao/predict1"
GB_IN="${CWDIR}/sge_jobs/light/${JB_LAB}" # [INPUT] generated by split
#test_arrayjobs


GB_DIR="/wynton/scratch/czhao/fastq" # Global scratch
GB_OUT="/wynton/scratch/czhao/predict1_mapping/bowtie2/light/${JB_LAB}"


TMPDIR="/scratch/czhao/light/${JB_LAB}"
LC_IN=${TMPDIR}/BT2_IN # Local scratch: copy FASTQ to here
LC_OUT=${TMPDIR}/BT2_OUT # generate SAM/BAM files here


if [ ! -d $TMPDIR ]; then
  mkdir -p $TMPDIR
fi


cd "$TMPDIR" # Use a temporary working directory
export TMPDIR


if [ ! -d $LC_IN ]; then
  mkdir -p $LC_IN
fi
if [ ! -d $LC_OUT ]; then
  mkdir -p $LC_OUT
fi
if [ “$(ls -A $LC_IN)” ]; then
	echo “not empty!!!”
	rm -vf $LC_IN/*
fi
if [ “$(ls -A $LC_OUT)” ]; then
	echo “not empty!!!”
	rm -vf $LC_OUT/*
fi
if [ ! -d $GB_OUT ]; then
  mkdir -p $GB_OUT
fi


GNUTIME="/wynton/home/pollard/czhao/local/bin/time-1.9/bin/time"
BT2_DB="/wynton/group/pollard/czhao/predict1/dbs/bt2_indexes/repgenomes"


while IFS= read -r SRA
do
  R_1="${GB_DIR}/${SRA}_1.fastq.gz"
  R_2="${GB_DIR}/${SRA}_2.fastq.gz"

  R1="${LC_IN}/${SRA}_1.fastq.gz"
  R2="${LC_IN}/${SRA}_2.fastq.gz"

  if [ ! -f $R1 ]; then
    cp -v $R_1 $R1
  fi
  if [ ! -f $R2 ]; then
    cp -v $R_2 $R2
  fi


  BT2_OUT="${LC_OUT}/${SRA}"
  if [ ! -d $BT2_OUT ]; then
    mkdir -p $BT2_OUT
  fi


  BAMFILE="${BT2_OUT}/${SRA}.raw.bam"
  bowtie2 --no-unal -x ${BT2_DB} -X 2000 --end-to-end --very-sensitive --threads ${TREADS} -q -1 $R1 -2 $R2 | samtools view --threads ${TREADS} -b - | samtools sort -m 2G --threads ${TREADS} -o $BAMFILE
  samtools index -@ ${TREADS} ${BAMFILE} ${BAMFILE}.bai


  TEMP_BAM="${BT2_OUT}/${SRA}.temp.bam"
  python3.7 ${CWDIR}/bin/filter_bam.py --bamfile ${BAMFILE} --outfile ${TEMP_BAM}


  FILTER_BAM="${BT2_OUT}/${SRA}.bam"
  samtools sort -m 2G -@ ${TREADS} -o ${FILTER_BAM} ${TEMP_BAM}
  samtools index -@ ${TREADS} ${FILTER_BAM} ${FILTER_BAM}.bai


  rm -v ${TEMP_BAM}
  mv -v $BT2_OUT/ $GB_OUT/
  rm -v $R1 $R2

  if [ ! -d $BT2_OUT ]; then echo “local scratch directory empty!“; else echo “failed to clear local scratch directory”; exit 9999; fi

  SUB_DIR=${CWDIR}
  if ls -A ${SUB_DIR}/ | grep core; then
    rm -v ${SUB_DIR}/core.*
  else
    echo “no core dumping detected”
  fi
done < ${GB_IN}


rm -vr $LC_IN
rm -vr $LC_OUT


SUB_DIR=${CWDIR}
if ls -A ${SUB_DIR}/ | grep core; then
	rm -v ${SUB_DIR}/core.*
else
	echo “no core dumping detected”
fi

conda deactivate


## End-of-job summary, if running as a job
#[[ -n "$JOB_ID" ]] && qstat -j "$JOB_ID"          # This is useful for debugging and usage purposes
